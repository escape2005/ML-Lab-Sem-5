{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PANFy1JbXqZt",
        "outputId": "e5ee263c-f037-4b1b-b311-c8e4b102b854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Ridge model...\n",
            "Training Lasso model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:2385: FutureWarning: 'store_cv_values' is deprecated in version 1.5 and will be removed in 1.7. Use 'store_cv_results' instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ElasticNet model...\n",
            "\n",
            "--- Ridge Results ---\n",
            "Best Alpha: 100.0\n",
            "R-squared (R²): 0.8693\n",
            "Root Mean Squared Error (RMSE): $32,365.32\n",
            "\n",
            "--- Lasso Results ---\n",
            "Best Alpha: 0.001\n",
            "R-squared (R²): 0.8627\n",
            "Root Mean Squared Error (RMSE): $33,176.13\n",
            "\n",
            "--- ElasticNet Results ---\n",
            "Best Alpha: 0.001\n",
            "R-squared (R²): 0.8640\n",
            "Root Mean Squared Error (RMSE): $33,025.48\n",
            "\n",
            "--- Lasso Feature Selection ---\n",
            "Lasso removed 4 features by setting their coefficients to zero.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# --- 1. Load and Prepare Data ---\n",
        "# Load your data from a local CSV file\n",
        "# IMPORTANT: Make sure to change 'your_ames_housing.csv' to the correct file path.\n",
        "file_path = '/content/AmesHousing.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    print(\"Please make sure the CSV file is in the same directory as the script or provide the full path.\")\n",
        "    # Exit or handle the error as needed\n",
        "    exit()\n",
        "\n",
        "\n",
        "# Select the same subset of features for the example.\n",
        "# You can adjust this list for your specific needs.\n",
        "features = [\n",
        "    'Lot Area', 'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add',\n",
        "    'BsmtFin SF 1', 'Total Bsmt SF', '1st Flr SF', '2nd Flr SF', 'Gr Liv Area',\n",
        "    'Full Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'TotRms AbvGrd', 'Fireplaces',\n",
        "    'Garage Cars', 'Garage Area', 'Wood Deck SF', 'Open Porch SF', 'MS Zoning', 'Neighborhood'\n",
        "]\n",
        "target = 'SalePrice'\n",
        "\n",
        "# Ensure all selected features and the target exist in the DataFrame\n",
        "required_columns = features + [target]\n",
        "missing_cols = [col for col in required_columns if col not in df.columns]\n",
        "if missing_cols:\n",
        "    print(f\"Error: The following required columns are missing from your CSV file: {missing_cols}\")\n",
        "    exit()\n",
        "\n",
        "df_subset = df[required_columns].copy()\n",
        "\n",
        "\n",
        "# --- 2. Preprocessing ---\n",
        "\n",
        "# A) Log-transform the target variable\n",
        "df_subset['SalePrice'] = np.log1p(df_subset['SalePrice'])\n",
        "\n",
        "# B) Separate numerical and categorical features\n",
        "numerical_features = df_subset.select_dtypes(include=np.number).columns.drop('SalePrice')\n",
        "categorical_features = df_subset.select_dtypes(include='object').columns\n",
        "\n",
        "# C) Handle Missing Values\n",
        "for col in numerical_features:\n",
        "    df_subset[col] = df_subset[col].fillna(df_subset[col].median())\n",
        "for col in categorical_features:\n",
        "    df_subset[col] = df_subset[col].fillna('None')\n",
        "\n",
        "# D) One-Hot Encode Categorical Features\n",
        "df_processed = pd.get_dummies(df_subset, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# --- 3. Splitting and Scaling ---\n",
        "\n",
        "X = df_processed.drop('SalePrice', axis=1)\n",
        "y = df_processed['SalePrice']\n",
        "\n",
        "# A) Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# B) Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# --- 4. Modeling ---\n",
        "\n",
        "alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "print(\"Training Ridge model...\")\n",
        "ridge = RidgeCV(alphas=alphas, store_cv_values=True)\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training Lasso model...\")\n",
        "lasso = LassoCV(alphas=alphas, cv=5, random_state=42)\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training ElasticNet model...\")\n",
        "elastic_net = ElasticNetCV(alphas=alphas, cv=5, random_state=42)\n",
        "elastic_net.fit(X_train, y_train)\n",
        "\n",
        "# --- 5. Evaluation ---\n",
        "\n",
        "models = {'Ridge': ridge, 'Lasso': lasso, 'ElasticNet': elastic_net}\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_orig = np.expm1(y_pred)\n",
        "    y_test_orig = np.expm1(y_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
        "    r2 = r2_score(y_test_orig, y_pred_orig)\n",
        "\n",
        "    print(f\"\\n--- {name} Results ---\")\n",
        "    print(f\"Best Alpha: {model.alpha_}\")\n",
        "    print(f\"R-squared (R²): {r2:.4f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
        "\n",
        "# --- 6. Lasso Feature Selection ---\n",
        "lasso_coefs = pd.Series(lasso.coef_, index=X.columns)\n",
        "removed_features = lasso_coefs[lasso_coefs == 0].index.tolist()\n",
        "\n",
        "print(\"\\n--- Lasso Feature Selection ---\")\n",
        "print(f\"Lasso removed {len(removed_features)} features by setting their coefficients to zero.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# --- 1. Generate a Synthetic Dataset ---\n",
        "# This mimics the properties of the Ames Housing data.\n",
        "print(\"Generating a synthetic dataset...\")\n",
        "np.random.seed(42)\n",
        "n_samples = 1500\n",
        "\n",
        "# Key predictive features\n",
        "overall_qual = np.random.randint(1, 11, n_samples)\n",
        "gr_liv_area = np.random.normal(1500, 400, n_samples) + overall_qual * 100\n",
        "garage_cars = np.random.randint(0, 5, n_samples)\n",
        "\n",
        "# Create multicollinearity\n",
        "total_bsmt_sf = gr_liv_area * np.random.normal(0.6, 0.1, n_samples)\n",
        "first_flr_sf = total_bsmt_sf * np.random.normal(0.7, 0.1, n_samples)\n",
        "\n",
        "# Categorical feature\n",
        "neighborhoods = ['Urban', 'Suburban', 'Rural']\n",
        "neighborhood = np.random.choice(neighborhoods, n_samples, p=[0.5, 0.4, 0.1])\n",
        "neighborhood_encoded = pd.get_dummies(neighborhood, drop_first=True, prefix='Neighborhood')\n",
        "\n",
        "# Noise features (less predictive)\n",
        "lot_area = np.random.normal(10000, 3000, n_samples)\n",
        "year_built = np.random.randint(1950, 2022, n_samples)\n",
        "\n",
        "# Define the relationship for the target variable (SalePrice)\n",
        "log_sale_price = (3 +\n",
        "                  overall_qual * 0.2 +\n",
        "                  gr_liv_area * 0.001 +\n",
        "                  garage_cars * 0.15 +\n",
        "                  total_bsmt_sf * 0.0005 +\n",
        "                  neighborhood_encoded['Neighborhood_Suburban'] * 0.1 +\n",
        "                  neighborhood_encoded['Neighborhood_Urban'] * 0.2 +\n",
        "                  np.random.normal(0, 0.1, n_samples)) # noise\n",
        "\n",
        "# Create the skewed SalePrice by taking the exponent\n",
        "sale_price = np.exp(log_sale_price)\n",
        "\n",
        "# Assemble the DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'SalePrice': sale_price,\n",
        "    'Overall Qual': overall_qual,\n",
        "    'Gr Liv Area': gr_liv_area,\n",
        "    'Garage Cars': garage_cars,\n",
        "    'Total Bsmt SF': total_bsmt_sf,\n",
        "    '1st Flr SF': first_flr_sf,\n",
        "    'Lot Area': lot_area,\n",
        "    'Year Built': year_built,\n",
        "    'Neighborhood': neighborhood\n",
        "})\n",
        "\n",
        "# Introduce some missing values\n",
        "df.loc[df.sample(frac=0.05).index, 'Total Bsmt SF'] = np.nan\n",
        "print(\"Synthetic dataset created successfully.\")\n",
        "\n",
        "# --- Visualization 1: Target Variable Distribution ---\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['SalePrice'], kde=True, bins=50)\n",
        "plt.title('Distribution of SalePrice (Original Synthetic)')\n",
        "\n",
        "df['SalePrice_log'] = np.log1p(df['SalePrice'])\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df['SalePrice_log'], kde=True, color='green', bins=50)\n",
        "plt.title('Distribution of SalePrice (Log-Transformed)')\n",
        "plt.xlabel('Log(SalePrice + 1)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('saleprice_distribution.png')\n",
        "print(\"Saved SalePrice distribution plot to saleprice_distribution.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# --- Visualization 2: Feature Correlation Heatmap ---\n",
        "corrmat = df.select_dtypes(include=[np.number]).corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corrmat, cbar=True, annot=True, fmt='.2f', cmap='viridis')\n",
        "plt.title('Correlation Heatmap of Synthetic Features')\n",
        "plt.savefig('correlation_heatmap.png')\n",
        "print(\"Saved correlation heatmap to correlation_heatmap.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# --- 2. Preprocessing ---\n",
        "df_subset = df.drop('SalePrice', axis=1)\n",
        "df_subset = df_subset.rename(columns={'SalePrice_log': 'SalePrice'})\n",
        "\n",
        "# Handle missing values for numerical columns\n",
        "for col in df_subset.select_dtypes(include=[np.number]).columns:\n",
        "    df_subset[col] = df_subset[col].fillna(df_subset[col].median())\n",
        "\n",
        "# One-hot encode categorical features\n",
        "df_processed = pd.get_dummies(df_subset, drop_first=True)\n",
        "\n",
        "# --- 3. Splitting and Scaling ---\n",
        "X = df_processed.drop('SalePrice', axis=1)\n",
        "y = df_processed['SalePrice']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# --- 4. Modeling (Lasso) ---\n",
        "alphas = [0.0001, 0.0005, 0.001, 0.01, 0.1]\n",
        "print(\"Training Lasso model...\")\n",
        "lasso = LassoCV(alphas=alphas, cv=5, random_state=42, max_iter=10000)\n",
        "lasso.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"\\n--- Lasso Model Results ---\")\n",
        "print(f\"Best Alpha found by Cross-Validation: {lasso.alpha_}\")\n",
        "\n",
        "\n",
        "# --- 5. Evaluation & Visualization ---\n",
        "y_pred_log = lasso.predict(X_test_scaled)\n",
        "y_pred_orig = np.expm1(y_pred_log)\n",
        "y_test_orig = np.expm1(y_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
        "r2 = r2_score(y_test_orig, y_pred_orig)\n",
        "\n",
        "print(f\"R-squared (R²): {r2:.4f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): ${rmse:,.2f}\")\n",
        "\n",
        "# --- Visualization 3: Predicted vs. Actual Values ---\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(y_test_orig, y_pred_orig, alpha=0.5, color='blue')\n",
        "plt.plot([min(y_test_orig), max(y_test_orig)], [min(y_test_orig), max(y_test_orig)], '--', color='red', lw=2)\n",
        "plt.xlabel('Actual Sale Price ($)')\n",
        "plt.ylabel('Predicted Sale Price ($)')\n",
        "plt.title('Lasso Model: Actual vs. Predicted Prices')\n",
        "plt.savefig('actual_vs_predicted.png')\n",
        "print(\"Saved Actual vs. Predicted plot to actual_vs_predicted.png\")\n",
        "plt.close()\n",
        "\n",
        "# --- Visualization 4: Residuals Plot ---\n",
        "residuals = y_test_orig - y_pred_orig\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=y_pred_orig, y=residuals, alpha=0.5)\n",
        "plt.axhline(y=0, color='red', linestyle='--')\n",
        "plt.xlabel('Predicted Sale Price ($)')\n",
        "plt.ylabel('Residuals ($)')\n",
        "plt.title('Lasso Model: Residuals Plot')\n",
        "plt.savefig('residuals_plot.png')\n",
        "print(\"Saved Residuals plot to residuals_plot.png\")\n",
        "plt.close()\n",
        "\n",
        "# --- Visualization 5: Feature Importance (Coefficients) ---\n",
        "lasso_coefs = pd.Series(lasso.coef_, index=X.columns)\n",
        "important_coefs = lasso_coefs[lasso_coefs.abs() > 0].sort_values()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "important_coefs.plot(kind='barh', color=important_coefs.apply(lambda x: 'g' if x > 0 else 'r'))\n",
        "plt.title('Lasso Model: Feature Coefficients (Synthetic Data)')\n",
        "plt.xlabel('Coefficient Value (Impact on Log-Price)')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.savefig('feature_importance.png')\n",
        "print(\"Saved Feature Importance plot to feature_importance.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HowhgJSraQt3",
        "outputId": "94b34d4a-439d-45a3-cf47-564ac294b893"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating a synthetic dataset...\n",
            "Synthetic dataset created successfully.\n",
            "Saved SalePrice distribution plot to saleprice_distribution.png\n",
            "Saved correlation heatmap to correlation_heatmap.png\n",
            "Training Lasso model...\n",
            "\n",
            "--- Lasso Model Results ---\n",
            "Best Alpha found by Cross-Validation: 0.0001\n",
            "R-squared (R²): 0.9853\n",
            "Root Mean Squared Error (RMSE): $391.83\n",
            "Saved Actual vs. Predicted plot to actual_vs_predicted.png\n",
            "Saved Residuals plot to residuals_plot.png\n",
            "Saved Feature Importance plot to feature_importance.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHLb5Ijxd3ZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}